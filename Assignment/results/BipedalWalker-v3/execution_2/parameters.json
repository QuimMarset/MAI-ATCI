{"reward_scale": 0.01, "num_envs": 8, "learning_rate": 0.0001, "grad_clipping": 50.0, "gamma": 0.99, "buffer_size": 512, "gae_lambda": 0.95, "epsilon": 0.2, "max_kl_diverg": 0.15, "epochs": 10, "train_experiments": 3, "train_episodes": 10000, "batch_size": 512, "iterations": 3000, "iteration_steps": 512}