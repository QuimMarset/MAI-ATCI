{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the PPO Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import LANDER, BIPEDAL\n",
    "from PPO.PPO_agent import DiscretePPOAgent, ContinuousPPOAgent\n",
    "from environments.environment import Environment\n",
    "from environments.vizdoom_environment import VizDoomEnvironment\n",
    "from utils.results_plotter import plot_test_results\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = './'\n",
    "results_path = os.path.join(root_path, 'results')\n",
    "weights_path = os.path.join(root_path, 'weights')\n",
    "\n",
    "lander_results_path = os.path.join(results_path, LANDER)\n",
    "lander_weights_path = os.path.join(weights_path, LANDER)\n",
    "\n",
    "bipedal_results_path = os.path.join(results_path, BIPEDAL)\n",
    "bipedal_weights_path = os.path.join(weights_path, BIPEDAL)\n",
    "\n",
    "basic_results_path = os.path.join(results_path, 'basic')\n",
    "basic_weights_path = os.path.join(weights_path, 'basic')\n",
    "\n",
    "health_results_path = os.path.join(results_path, 'health_gathering')\n",
    "health_weights_path = os.path.join(weights_path, 'health_gathering')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to test the environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_environment(environment_name, render):\n",
    "    if environment_name == 'basic' or environment_name == 'health_gathering':\n",
    "        env = VizDoomEnvironment(environment_name, render=render)\n",
    "    else:\n",
    "        env = Environment(environment_name, render=render)\n",
    "    return env\n",
    "\n",
    "def create_test_agent(environment_name, state_shape, action_space, weights_path):\n",
    "    if environment_name == 'basic' or environment_name == 'health_gathering':\n",
    "        num_actions = action_space\n",
    "        agent = DiscretePPOAgent.test(weights_path, state_shape, num_actions)\n",
    "    else:\n",
    "        action_space_info = (action_space.shape[0], action_space.low, action_space.high)\n",
    "        agent = ContinuousPPOAgent.test(weights_path, state_shape, action_space_info)\n",
    "    return agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_agent(results_path, weights_path, environment_name, render=True):\n",
    "    env = create_test_environment(environment_name, render)\n",
    "    state_shape = env.get_state_shape()\n",
    "    action_space = env.get_action_space()\n",
    "    agent = create_test_agent(environment_name, state_shape, action_space, weights_path)\n",
    "\n",
    "    test_episodes = 100\n",
    "    episode_rewards = []\n",
    "    sleep_time = 0.05 if (environment_name == 'basic' or environment_name == 'health_gathering') else 0\n",
    "\n",
    "    for i in range(test_episodes):\n",
    "        done = False\n",
    "        state = env.start()\n",
    "        total_reward = 0\n",
    "\n",
    "        while not done:\n",
    "            action = agent.test_step(state)\n",
    "            next_state, reward, done = env.step(action)\n",
    "            total_reward += reward\n",
    "            state = next_state\n",
    "\n",
    "            # Slow a little bit the ViZDoom environments to appreciate the visualization\n",
    "            sleep(sleep_time)\n",
    "\n",
    "        episode_rewards.append(total_reward)\n",
    "        print(f'Episode {i+1}/{test_episodes}: Reward: {total_reward:.2f}')\n",
    "\n",
    "    avg_reward = np.mean(episode_rewards)\n",
    "    print(f'Avg reward of {test_episodes} episodes: {avg_reward}')\n",
    "    plot_test_results(episode_rewards, environment_name, results_path)\n",
    "    env.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test PPO on LunarLanderContinuous-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1/100: Reward: 310.31\n",
      "Episode 2/100: Reward: 277.10\n",
      "Episode 3/100: Reward: 273.31\n",
      "Episode 4/100: Reward: 261.94\n",
      "Episode 5/100: Reward: 284.80\n",
      "Episode 6/100: Reward: 226.71\n",
      "Episode 7/100: Reward: 286.23\n",
      "Episode 8/100: Reward: 273.18\n",
      "Episode 9/100: Reward: 292.83\n",
      "Episode 10/100: Reward: 284.18\n",
      "Episode 11/100: Reward: 270.04\n",
      "Episode 12/100: Reward: 279.72\n",
      "Episode 13/100: Reward: 290.73\n",
      "Episode 14/100: Reward: 242.16\n",
      "Episode 15/100: Reward: 243.59\n",
      "Episode 16/100: Reward: 304.38\n",
      "Episode 17/100: Reward: 244.41\n",
      "Episode 18/100: Reward: 296.36\n",
      "Episode 19/100: Reward: 307.58\n",
      "Episode 20/100: Reward: 306.25\n",
      "Episode 21/100: Reward: 270.45\n",
      "Episode 22/100: Reward: 295.65\n",
      "Episode 23/100: Reward: 286.25\n",
      "Episode 24/100: Reward: 223.10\n",
      "Episode 25/100: Reward: 302.86\n",
      "Episode 26/100: Reward: 287.06\n",
      "Episode 27/100: Reward: 272.32\n",
      "Episode 28/100: Reward: 243.00\n",
      "Episode 29/100: Reward: 274.29\n",
      "Episode 30/100: Reward: 304.58\n",
      "Episode 31/100: Reward: 285.99\n",
      "Episode 32/100: Reward: 295.91\n",
      "Episode 33/100: Reward: 278.74\n",
      "Episode 34/100: Reward: 250.16\n",
      "Episode 35/100: Reward: 285.95\n",
      "Episode 36/100: Reward: 264.13\n",
      "Episode 37/100: Reward: 276.03\n",
      "Episode 38/100: Reward: 289.93\n",
      "Episode 39/100: Reward: 310.89\n",
      "Episode 40/100: Reward: 309.27\n",
      "Episode 41/100: Reward: 306.76\n",
      "Episode 42/100: Reward: 296.80\n",
      "Episode 43/100: Reward: 296.86\n",
      "Episode 44/100: Reward: 277.09\n",
      "Episode 45/100: Reward: 277.91\n",
      "Episode 46/100: Reward: 280.94\n",
      "Episode 47/100: Reward: 274.92\n",
      "Episode 48/100: Reward: 293.45\n",
      "Episode 49/100: Reward: 302.10\n",
      "Episode 50/100: Reward: 303.78\n",
      "Episode 51/100: Reward: 235.09\n",
      "Episode 52/100: Reward: 265.83\n",
      "Episode 53/100: Reward: 261.13\n",
      "Episode 54/100: Reward: 291.10\n",
      "Episode 55/100: Reward: 231.98\n",
      "Episode 56/100: Reward: 268.89\n",
      "Episode 57/100: Reward: 300.67\n",
      "Episode 58/100: Reward: 282.45\n",
      "Episode 59/100: Reward: 280.70\n",
      "Episode 60/100: Reward: 271.12\n",
      "Episode 61/100: Reward: 303.56\n",
      "Episode 62/100: Reward: 309.28\n",
      "Episode 63/100: Reward: 294.88\n",
      "Episode 64/100: Reward: 275.78\n",
      "Episode 65/100: Reward: 296.08\n",
      "Episode 66/100: Reward: 254.24\n",
      "Episode 67/100: Reward: 272.20\n",
      "Episode 68/100: Reward: 303.20\n",
      "Episode 69/100: Reward: 263.82\n",
      "Episode 70/100: Reward: 304.70\n",
      "Episode 71/100: Reward: 299.11\n",
      "Episode 72/100: Reward: 271.67\n",
      "Episode 73/100: Reward: 300.70\n",
      "Episode 74/100: Reward: 261.49\n",
      "Episode 75/100: Reward: 239.64\n",
      "Episode 76/100: Reward: 304.28\n",
      "Episode 77/100: Reward: 310.77\n",
      "Episode 78/100: Reward: 264.11\n",
      "Episode 79/100: Reward: 304.92\n",
      "Episode 80/100: Reward: 239.75\n",
      "Episode 81/100: Reward: 288.51\n",
      "Episode 82/100: Reward: 296.18\n",
      "Episode 83/100: Reward: 293.43\n",
      "Episode 84/100: Reward: 296.28\n",
      "Episode 85/100: Reward: 256.80\n",
      "Episode 86/100: Reward: 325.65\n",
      "Episode 87/100: Reward: 278.25\n",
      "Episode 88/100: Reward: 289.37\n",
      "Episode 89/100: Reward: 316.48\n",
      "Episode 90/100: Reward: 273.37\n",
      "Episode 91/100: Reward: 294.31\n",
      "Episode 92/100: Reward: 268.56\n",
      "Episode 93/100: Reward: 259.49\n",
      "Episode 94/100: Reward: 285.19\n",
      "Episode 95/100: Reward: 290.59\n",
      "Episode 96/100: Reward: 286.90\n",
      "Episode 97/100: Reward: 261.34\n",
      "Episode 98/100: Reward: 288.18\n",
      "Episode 99/100: Reward: 298.33\n",
      "Episode 100/100: Reward: 283.67\n",
      "Avg reward of 100 episodes: 281.66947445000875\n"
     ]
    }
   ],
   "source": [
    "best_lander_results_path = os.path.join(lander_results_path, 'execution_2')\n",
    "best_lander_weights_path = os.path.join(lander_weights_path, 'execution_2')\n",
    "\n",
    "test_agent(best_lander_results_path, best_lander_weights_path, LANDER, render=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test PPO on BipedalWalker-v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1/100: Reward: 316.29\n",
      "Episode 2/100: Reward: 84.69\n",
      "Episode 3/100: Reward: 317.45\n",
      "Episode 4/100: Reward: 317.74\n",
      "Episode 5/100: Reward: 316.13\n",
      "Episode 6/100: Reward: 316.14\n",
      "Episode 7/100: Reward: 316.38\n",
      "Episode 8/100: Reward: 317.24\n",
      "Episode 9/100: Reward: 316.96\n",
      "Episode 10/100: Reward: 317.09\n",
      "Episode 11/100: Reward: -80.62\n",
      "Episode 12/100: Reward: 317.59\n",
      "Episode 13/100: Reward: 316.47\n",
      "Episode 14/100: Reward: 316.81\n",
      "Episode 15/100: Reward: 122.03\n",
      "Episode 16/100: Reward: 316.58\n",
      "Episode 17/100: Reward: 316.45\n",
      "Episode 18/100: Reward: 315.81\n",
      "Episode 19/100: Reward: 317.17\n",
      "Episode 20/100: Reward: 317.62\n",
      "Episode 21/100: Reward: 156.47\n",
      "Episode 22/100: Reward: 61.37\n",
      "Episode 23/100: Reward: 315.95\n",
      "Episode 24/100: Reward: 318.67\n",
      "Episode 25/100: Reward: 316.33\n",
      "Episode 26/100: Reward: 315.56\n",
      "Episode 27/100: Reward: 316.00\n",
      "Episode 28/100: Reward: 316.57\n",
      "Episode 29/100: Reward: -29.92\n",
      "Episode 30/100: Reward: 77.09\n",
      "Episode 31/100: Reward: 315.26\n",
      "Episode 32/100: Reward: 317.00\n",
      "Episode 33/100: Reward: 125.82\n",
      "Episode 34/100: Reward: 315.51\n",
      "Episode 35/100: Reward: 316.34\n",
      "Episode 36/100: Reward: 318.13\n",
      "Episode 37/100: Reward: 317.64\n",
      "Episode 38/100: Reward: 316.20\n",
      "Episode 39/100: Reward: 34.24\n",
      "Episode 40/100: Reward: 64.60\n",
      "Episode 41/100: Reward: 166.27\n",
      "Episode 42/100: Reward: 317.48\n",
      "Episode 43/100: Reward: 123.54\n",
      "Episode 44/100: Reward: -50.32\n",
      "Episode 45/100: Reward: 316.05\n",
      "Episode 46/100: Reward: 317.60\n",
      "Episode 47/100: Reward: 316.17\n",
      "Episode 48/100: Reward: 114.81\n",
      "Episode 49/100: Reward: 317.25\n",
      "Episode 50/100: Reward: 316.20\n",
      "Episode 51/100: Reward: 318.54\n",
      "Episode 52/100: Reward: 317.41\n",
      "Episode 53/100: Reward: 10.45\n",
      "Episode 54/100: Reward: 315.62\n",
      "Episode 55/100: Reward: -57.42\n",
      "Episode 56/100: Reward: 316.93\n",
      "Episode 57/100: Reward: 317.13\n",
      "Episode 58/100: Reward: 317.81\n",
      "Episode 59/100: Reward: 318.41\n",
      "Episode 60/100: Reward: 103.23\n",
      "Episode 61/100: Reward: 316.18\n",
      "Episode 62/100: Reward: 315.94\n",
      "Episode 63/100: Reward: 316.92\n",
      "Episode 64/100: Reward: -67.45\n",
      "Episode 65/100: Reward: 317.87\n",
      "Episode 66/100: Reward: 315.79\n",
      "Episode 67/100: Reward: 124.61\n",
      "Episode 68/100: Reward: 317.20\n",
      "Episode 69/100: Reward: 11.09\n",
      "Episode 70/100: Reward: 316.06\n",
      "Episode 71/100: Reward: 314.88\n",
      "Episode 72/100: Reward: 317.09\n",
      "Episode 73/100: Reward: 188.02\n",
      "Episode 74/100: Reward: 316.89\n",
      "Episode 75/100: Reward: 317.45\n",
      "Episode 76/100: Reward: 315.00\n",
      "Episode 77/100: Reward: 318.78\n",
      "Episode 78/100: Reward: 315.30\n",
      "Episode 79/100: Reward: 315.65\n",
      "Episode 80/100: Reward: 316.18\n",
      "Episode 81/100: Reward: 120.28\n",
      "Episode 82/100: Reward: 100.95\n",
      "Episode 83/100: Reward: 314.77\n",
      "Episode 84/100: Reward: 316.32\n",
      "Episode 85/100: Reward: 316.02\n",
      "Episode 86/100: Reward: 316.43\n",
      "Episode 87/100: Reward: 317.48\n",
      "Episode 88/100: Reward: 315.49\n",
      "Episode 89/100: Reward: 317.10\n",
      "Episode 90/100: Reward: 314.83\n",
      "Episode 91/100: Reward: 318.02\n",
      "Episode 92/100: Reward: 316.17\n",
      "Episode 93/100: Reward: 316.72\n",
      "Episode 94/100: Reward: 67.16\n",
      "Episode 95/100: Reward: 107.65\n",
      "Episode 96/100: Reward: -63.35\n",
      "Episode 97/100: Reward: -14.01\n",
      "Episode 98/100: Reward: 317.63\n",
      "Episode 99/100: Reward: 315.80\n",
      "Episode 100/100: Reward: 316.23\n",
      "Avg reward of 100 episodes: 247.17185289859017\n"
     ]
    }
   ],
   "source": [
    "# This execution contains the weights and results of the first execution which learns to walk in the safest way\n",
    "\n",
    "bipedal_results_1_path = os.path.join(bipedal_results_path, 'execution_1')\n",
    "bipedal_weights_1_path = os.path.join(bipedal_weights_path, 'execution_1')\n",
    "\n",
    "test_agent(bipedal_results_1_path, bipedal_weights_1_path, BIPEDAL, render=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1/100: Reward: 324.56\n",
      "Episode 2/100: Reward: 322.05\n",
      "Episode 3/100: Reward: 323.71\n",
      "Episode 4/100: Reward: 323.95\n",
      "Episode 5/100: Reward: 324.95\n",
      "Episode 6/100: Reward: 322.93\n",
      "Episode 7/100: Reward: 317.38\n",
      "Episode 8/100: Reward: 323.43\n",
      "Episode 9/100: Reward: 324.55\n",
      "Episode 10/100: Reward: 324.49\n",
      "Episode 11/100: Reward: 325.29\n",
      "Episode 12/100: Reward: 324.01\n",
      "Episode 13/100: Reward: 324.19\n",
      "Episode 14/100: Reward: 323.99\n",
      "Episode 15/100: Reward: 324.70\n",
      "Episode 16/100: Reward: 325.28\n",
      "Episode 17/100: Reward: 324.34\n",
      "Episode 18/100: Reward: 324.06\n",
      "Episode 19/100: Reward: 325.11\n",
      "Episode 20/100: Reward: 323.80\n",
      "Episode 21/100: Reward: 324.49\n",
      "Episode 22/100: Reward: 324.14\n",
      "Episode 23/100: Reward: 325.21\n",
      "Episode 24/100: Reward: 323.45\n",
      "Episode 25/100: Reward: 325.75\n",
      "Episode 26/100: Reward: 324.07\n",
      "Episode 27/100: Reward: 324.66\n",
      "Episode 28/100: Reward: 324.99\n",
      "Episode 29/100: Reward: 323.08\n",
      "Episode 30/100: Reward: 324.06\n",
      "Episode 31/100: Reward: 324.32\n",
      "Episode 32/100: Reward: 324.35\n",
      "Episode 33/100: Reward: 324.88\n",
      "Episode 34/100: Reward: 324.70\n",
      "Episode 35/100: Reward: 323.77\n",
      "Episode 36/100: Reward: 325.48\n",
      "Episode 37/100: Reward: 324.59\n",
      "Episode 38/100: Reward: 323.43\n",
      "Episode 39/100: Reward: 323.75\n",
      "Episode 40/100: Reward: 323.93\n",
      "Episode 41/100: Reward: 322.47\n",
      "Episode 42/100: Reward: 325.36\n",
      "Episode 43/100: Reward: 321.76\n",
      "Episode 44/100: Reward: 322.96\n",
      "Episode 45/100: Reward: 324.05\n",
      "Episode 46/100: Reward: 324.26\n",
      "Episode 47/100: Reward: 323.73\n",
      "Episode 48/100: Reward: 324.60\n",
      "Episode 49/100: Reward: 325.02\n",
      "Episode 50/100: Reward: 194.19\n",
      "Episode 51/100: Reward: 325.44\n",
      "Episode 52/100: Reward: 323.28\n",
      "Episode 53/100: Reward: 323.87\n",
      "Episode 54/100: Reward: 323.83\n",
      "Episode 55/100: Reward: 324.41\n",
      "Episode 56/100: Reward: 326.32\n",
      "Episode 57/100: Reward: 324.14\n",
      "Episode 58/100: Reward: 324.56\n",
      "Episode 59/100: Reward: 322.52\n",
      "Episode 60/100: Reward: 324.58\n",
      "Episode 61/100: Reward: 324.71\n",
      "Episode 62/100: Reward: 324.12\n",
      "Episode 63/100: Reward: 324.79\n",
      "Episode 64/100: Reward: 323.91\n",
      "Episode 65/100: Reward: 324.76\n",
      "Episode 66/100: Reward: 325.05\n",
      "Episode 67/100: Reward: 324.93\n",
      "Episode 68/100: Reward: 325.03\n",
      "Episode 69/100: Reward: 322.89\n",
      "Episode 70/100: Reward: 324.82\n",
      "Episode 71/100: Reward: 324.33\n",
      "Episode 72/100: Reward: 323.79\n",
      "Episode 73/100: Reward: 324.54\n",
      "Episode 74/100: Reward: 323.83\n",
      "Episode 75/100: Reward: 323.80\n",
      "Episode 76/100: Reward: 323.29\n",
      "Episode 77/100: Reward: 325.20\n",
      "Episode 78/100: Reward: 323.93\n",
      "Episode 79/100: Reward: 323.79\n",
      "Episode 80/100: Reward: 325.07\n",
      "Episode 81/100: Reward: 323.84\n",
      "Episode 82/100: Reward: 323.04\n",
      "Episode 83/100: Reward: 324.90\n",
      "Episode 84/100: Reward: 324.97\n",
      "Episode 85/100: Reward: 324.39\n",
      "Episode 86/100: Reward: 323.70\n",
      "Episode 87/100: Reward: 324.48\n",
      "Episode 88/100: Reward: 324.37\n",
      "Episode 89/100: Reward: 324.24\n",
      "Episode 90/100: Reward: 322.33\n",
      "Episode 91/100: Reward: 322.66\n",
      "Episode 92/100: Reward: 323.57\n",
      "Episode 93/100: Reward: 324.22\n",
      "Episode 94/100: Reward: 324.78\n",
      "Episode 95/100: Reward: 323.67\n",
      "Episode 96/100: Reward: 323.85\n",
      "Episode 97/100: Reward: 325.61\n",
      "Episode 98/100: Reward: 323.87\n",
      "Episode 99/100: Reward: 323.26\n",
      "Episode 100/100: Reward: 323.88\n",
      "Avg reward of 100 episodes: 322.8142409462961\n"
     ]
    }
   ],
   "source": [
    "# This execution contains the weights and results of the second execution which learns to walk better, but not in the fastest way\n",
    "\n",
    "bipedal_results_2_path = os.path.join(bipedal_results_path, 'execution_2')\n",
    "bipedal_weights_2_path = os.path.join(bipedal_weights_path, 'execution_2')\n",
    "\n",
    "test_agent(bipedal_results_2_path, bipedal_weights_2_path, BIPEDAL,render=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test PPO on ViZDoom basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1/100: Reward: 95.00\n",
      "Episode 2/100: Reward: 79.00\n",
      "Episode 3/100: Reward: 79.00\n",
      "Episode 4/100: Reward: 95.00\n",
      "Episode 5/100: Reward: 75.00\n",
      "Episode 6/100: Reward: 95.00\n",
      "Episode 7/100: Reward: 95.00\n",
      "Episode 8/100: Reward: 95.00\n",
      "Episode 9/100: Reward: 75.00\n",
      "Episode 10/100: Reward: 79.00\n",
      "Episode 11/100: Reward: 87.00\n",
      "Episode 12/100: Reward: 95.00\n",
      "Episode 13/100: Reward: 79.00\n",
      "Episode 14/100: Reward: 71.00\n",
      "Episode 15/100: Reward: 91.00\n",
      "Episode 16/100: Reward: 95.00\n",
      "Episode 17/100: Reward: 95.00\n",
      "Episode 18/100: Reward: 83.00\n",
      "Episode 19/100: Reward: 95.00\n",
      "Episode 20/100: Reward: 95.00\n",
      "Episode 21/100: Reward: 87.00\n",
      "Episode 22/100: Reward: 95.00\n",
      "Episode 23/100: Reward: 64.00\n",
      "Episode 24/100: Reward: 71.00\n",
      "Episode 25/100: Reward: 67.00\n",
      "Episode 26/100: Reward: 95.00\n",
      "Episode 27/100: Reward: 87.00\n",
      "Episode 28/100: Reward: 67.00\n",
      "Episode 29/100: Reward: 95.00\n",
      "Episode 30/100: Reward: 95.00\n",
      "Episode 31/100: Reward: 95.00\n",
      "Episode 32/100: Reward: 95.00\n",
      "Episode 33/100: Reward: 71.00\n",
      "Episode 34/100: Reward: 95.00\n",
      "Episode 35/100: Reward: 95.00\n",
      "Episode 36/100: Reward: 71.00\n",
      "Episode 37/100: Reward: 95.00\n",
      "Episode 38/100: Reward: 91.00\n",
      "Episode 39/100: Reward: 95.00\n",
      "Episode 40/100: Reward: 87.00\n",
      "Episode 41/100: Reward: 67.00\n",
      "Episode 42/100: Reward: 95.00\n",
      "Episode 43/100: Reward: 87.00\n",
      "Episode 44/100: Reward: 71.00\n",
      "Episode 45/100: Reward: 95.00\n",
      "Episode 46/100: Reward: 95.00\n",
      "Episode 47/100: Reward: 83.00\n",
      "Episode 48/100: Reward: 95.00\n",
      "Episode 49/100: Reward: 95.00\n",
      "Episode 50/100: Reward: 68.00\n",
      "Episode 51/100: Reward: 91.00\n",
      "Episode 52/100: Reward: 95.00\n",
      "Episode 53/100: Reward: 95.00\n",
      "Episode 54/100: Reward: 79.00\n",
      "Episode 55/100: Reward: 87.00\n",
      "Episode 56/100: Reward: 95.00\n",
      "Episode 57/100: Reward: 95.00\n",
      "Episode 58/100: Reward: 67.00\n",
      "Episode 59/100: Reward: 83.00\n",
      "Episode 60/100: Reward: 95.00\n",
      "Episode 61/100: Reward: 95.00\n",
      "Episode 62/100: Reward: 95.00\n",
      "Episode 63/100: Reward: 95.00\n",
      "Episode 64/100: Reward: 83.00\n",
      "Episode 65/100: Reward: 95.00\n",
      "Episode 66/100: Reward: 75.00\n",
      "Episode 67/100: Reward: 95.00\n",
      "Episode 68/100: Reward: 95.00\n",
      "Episode 69/100: Reward: 67.00\n",
      "Episode 70/100: Reward: 95.00\n",
      "Episode 71/100: Reward: 95.00\n",
      "Episode 72/100: Reward: 71.00\n",
      "Episode 73/100: Reward: 67.00\n",
      "Episode 74/100: Reward: 37.00\n",
      "Episode 75/100: Reward: 95.00\n",
      "Episode 76/100: Reward: 95.00\n",
      "Episode 77/100: Reward: 95.00\n",
      "Episode 78/100: Reward: 95.00\n",
      "Episode 79/100: Reward: 95.00\n",
      "Episode 80/100: Reward: 83.00\n",
      "Episode 81/100: Reward: 64.00\n",
      "Episode 82/100: Reward: 91.00\n",
      "Episode 83/100: Reward: 95.00\n",
      "Episode 84/100: Reward: 87.00\n",
      "Episode 85/100: Reward: 68.00\n",
      "Episode 86/100: Reward: 95.00\n",
      "Episode 87/100: Reward: 95.00\n",
      "Episode 88/100: Reward: 91.00\n",
      "Episode 89/100: Reward: 79.00\n",
      "Episode 90/100: Reward: 75.00\n",
      "Episode 91/100: Reward: 87.00\n",
      "Episode 92/100: Reward: 64.00\n",
      "Episode 93/100: Reward: 95.00\n",
      "Episode 94/100: Reward: 95.00\n",
      "Episode 95/100: Reward: 83.00\n",
      "Episode 96/100: Reward: 83.00\n",
      "Episode 97/100: Reward: 95.00\n",
      "Episode 98/100: Reward: 75.00\n",
      "Episode 99/100: Reward: 95.00\n",
      "Episode 100/100: Reward: 83.00\n",
      "Avg reward of 100 episodes: 86.07\n"
     ]
    }
   ],
   "source": [
    "basic_results_1_path = os.path.join(basic_results_path, 'execution_1')\n",
    "basic_weights_1_path = os.path.join(basic_weights_path, 'execution_1')\n",
    "\n",
    "test_agent(basic_results_1_path, basic_weights_1_path, 'basic', render=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test PPO on ViZDoom health_gathering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1/100: Reward: 2100.00\n",
      "Episode 2/100: Reward: 2100.00\n",
      "Episode 3/100: Reward: 2100.00\n",
      "Episode 4/100: Reward: 2100.00\n",
      "Episode 5/100: Reward: 2100.00\n",
      "Episode 6/100: Reward: 2100.00\n",
      "Episode 7/100: Reward: 2100.00\n",
      "Episode 8/100: Reward: 2100.00\n",
      "Episode 9/100: Reward: 2100.00\n",
      "Episode 10/100: Reward: 2100.00\n",
      "Episode 11/100: Reward: 2100.00\n",
      "Episode 12/100: Reward: 2100.00\n",
      "Episode 13/100: Reward: 2100.00\n",
      "Episode 14/100: Reward: 2100.00\n",
      "Episode 15/100: Reward: 2100.00\n",
      "Episode 16/100: Reward: 2100.00\n",
      "Episode 17/100: Reward: 2100.00\n",
      "Episode 18/100: Reward: 2100.00\n",
      "Episode 19/100: Reward: 2100.00\n",
      "Episode 20/100: Reward: 2100.00\n",
      "Episode 21/100: Reward: 2100.00\n",
      "Episode 22/100: Reward: 2100.00\n",
      "Episode 23/100: Reward: 2100.00\n",
      "Episode 24/100: Reward: 2100.00\n",
      "Episode 25/100: Reward: 2100.00\n",
      "Episode 26/100: Reward: 2100.00\n",
      "Episode 27/100: Reward: 2100.00\n",
      "Episode 28/100: Reward: 2100.00\n",
      "Episode 29/100: Reward: 2100.00\n",
      "Episode 30/100: Reward: 2100.00\n",
      "Episode 31/100: Reward: 2100.00\n",
      "Episode 32/100: Reward: 2100.00\n",
      "Episode 33/100: Reward: 2100.00\n",
      "Episode 34/100: Reward: 2100.00\n",
      "Episode 35/100: Reward: 2100.00\n",
      "Episode 36/100: Reward: 2100.00\n",
      "Episode 37/100: Reward: 2100.00\n",
      "Episode 38/100: Reward: 2100.00\n",
      "Episode 39/100: Reward: 2100.00\n",
      "Episode 40/100: Reward: 2100.00\n",
      "Episode 41/100: Reward: 2100.00\n",
      "Episode 42/100: Reward: 2100.00\n",
      "Episode 43/100: Reward: 2100.00\n",
      "Episode 44/100: Reward: 2100.00\n",
      "Episode 45/100: Reward: 2100.00\n",
      "Episode 46/100: Reward: 2100.00\n",
      "Episode 47/100: Reward: 2100.00\n",
      "Episode 48/100: Reward: 2100.00\n",
      "Episode 49/100: Reward: 2100.00\n",
      "Episode 50/100: Reward: 2100.00\n",
      "Episode 51/100: Reward: 2100.00\n",
      "Episode 52/100: Reward: 2100.00\n",
      "Episode 53/100: Reward: 2100.00\n",
      "Episode 54/100: Reward: 2100.00\n",
      "Episode 55/100: Reward: 2100.00\n",
      "Episode 56/100: Reward: 2100.00\n",
      "Episode 57/100: Reward: 2100.00\n",
      "Episode 58/100: Reward: 2100.00\n",
      "Episode 59/100: Reward: 2100.00\n",
      "Episode 60/100: Reward: 2100.00\n",
      "Episode 61/100: Reward: 2100.00\n",
      "Episode 62/100: Reward: 2100.00\n",
      "Episode 63/100: Reward: 2100.00\n",
      "Episode 64/100: Reward: 2100.00\n",
      "Episode 65/100: Reward: 2100.00\n",
      "Episode 66/100: Reward: 2100.00\n",
      "Episode 67/100: Reward: 2100.00\n",
      "Episode 68/100: Reward: 2100.00\n",
      "Episode 69/100: Reward: 2100.00\n",
      "Episode 70/100: Reward: 2100.00\n",
      "Episode 71/100: Reward: 2100.00\n",
      "Episode 72/100: Reward: 2100.00\n",
      "Episode 73/100: Reward: 2100.00\n",
      "Episode 74/100: Reward: 2100.00\n",
      "Episode 75/100: Reward: 2100.00\n",
      "Episode 76/100: Reward: 2100.00\n",
      "Episode 77/100: Reward: 2100.00\n",
      "Episode 78/100: Reward: 2100.00\n",
      "Episode 79/100: Reward: 2100.00\n",
      "Episode 80/100: Reward: 2100.00\n",
      "Episode 81/100: Reward: 2100.00\n",
      "Episode 82/100: Reward: 2100.00\n",
      "Episode 83/100: Reward: 2100.00\n",
      "Episode 84/100: Reward: 2100.00\n",
      "Episode 85/100: Reward: 2100.00\n",
      "Episode 86/100: Reward: 2100.00\n",
      "Episode 87/100: Reward: 2100.00\n",
      "Episode 88/100: Reward: 2100.00\n",
      "Episode 89/100: Reward: 2100.00\n",
      "Episode 90/100: Reward: 2100.00\n",
      "Episode 91/100: Reward: 2100.00\n",
      "Episode 92/100: Reward: 2100.00\n",
      "Episode 93/100: Reward: 2100.00\n",
      "Episode 94/100: Reward: 2100.00\n",
      "Episode 95/100: Reward: 2100.00\n",
      "Episode 96/100: Reward: 2100.00\n",
      "Episode 97/100: Reward: 2100.00\n",
      "Episode 98/100: Reward: 2100.00\n",
      "Episode 99/100: Reward: 2100.00\n",
      "Episode 100/100: Reward: 2100.00\n",
      "Avg reward of 100 episodes: 2100.0\n"
     ]
    }
   ],
   "source": [
    "health_results_1_path = os.path.join(health_results_path, 'execution_1')\n",
    "health_weights_1_path = os.path.join(health_weights_path, 'execution_1')\n",
    "\n",
    "test_agent(health_results_1_path, health_weights_1_path, 'health_gathering', render=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0700c7f74b45c332d3cae75f71229e241bbc846b934be310d892912689fa2754"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
