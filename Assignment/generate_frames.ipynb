{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import BIPEDAL\n",
    "from PPO.PPO_agent import  ContinuousPPOAgent\n",
    "\n",
    "import os\n",
    "import gym\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = './'\n",
    "weights_path = os.path.join(root_path, 'weights', BIPEDAL)\n",
    "weights_1_path = os.path.join(weights_path, 'execution_1')\n",
    "weights_2_path = os.path.join(weights_path, 'execution_2')\n",
    "\n",
    "frames_path = os.path.join(root_path, 'frames')\n",
    "frames_1_path = os.path.join(frames_path, 'experiment_1')\n",
    "frames_2_path = os.path.join(frames_path, 'experiment_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(frames_path, exist_ok=True)\n",
    "os.makedirs(frames_1_path, exist_ok=True)\n",
    "os.makedirs(frames_2_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_agent(weights_path, frames_path):\n",
    "    env = gym.make(BIPEDAL)\n",
    "    state_shape = env.observation_space.shape\n",
    "    action_space = env.action_space\n",
    "    action_space_info = (action_space.shape[0], action_space.low, action_space.high)\n",
    "\n",
    "    agent = ContinuousPPOAgent.test(weights_path, state_shape, action_space_info)\n",
    "\n",
    "    for i in range(2):\n",
    "\n",
    "        episode_frames = os.path.join(frames_path, f'episode_{i}')\n",
    "        os.makedirs(episode_frames, exist_ok=True)\n",
    "\n",
    "        done = False\n",
    "        state = env.reset()\n",
    "        total_reward = 0\n",
    "        t = 0\n",
    "\n",
    "        while not done:\n",
    "            action = agent.test_step(state)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            total_reward += reward\n",
    "            state = next_state\n",
    "\n",
    "            img = env.render(mode = 'rgb_array')\n",
    "            img = Image.fromarray(img)\n",
    "            img.save(os.path.join(episode_frames, f'frame_{t}.jpg'))\n",
    "\n",
    "            t += 1\n",
    "\n",
    "        print(f'Episode {i+1}: Reward: {total_reward:.2f}')\n",
    "    \n",
    "    env.close()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: Reward: 316.76\n",
      "Episode 2: Reward: 316.67\n",
      "Episode 1: Reward: 324.36\n",
      "Episode 2: Reward: 324.44\n"
     ]
    }
   ],
   "source": [
    "test_agent(weights_1_path, frames_1_path)\n",
    "test_agent(weights_2_path, frames_2_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import deque\n",
    "import os\n",
    "import json\n",
    "from constants import *\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "root_path = './'\n",
    "results_path = os.path.join(root_path, 'results', 'health_gathering', 'execution_3')\n",
    "file_path = os.path.join(results_path, 'train_results.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_path, 'rb') as file:\n",
    "    rewards = np.load(file)\n",
    "    actor_loss = np.load(file)\n",
    "    critic_loss = np.load(file)\n",
    "    kl_divergence = np.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3000)\n",
      "(3, 1000)\n",
      "(3, 1000)\n",
      "(3, 1000)\n"
     ]
    }
   ],
   "source": [
    "print(rewards.shape)\n",
    "print(actor_loss.shape)\n",
    "print(critic_loss.shape)\n",
    "print(kl_divergence.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _plot_rewards_results(rewards):\n",
    "    data = rewards[:2, :2000]\n",
    "    means = np.mean(data, axis=0)\n",
    "    stds = np.std(data, axis=0)\n",
    "\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    plt.plot(means, label='mean')\n",
    "    plt.fill_between(range(means.shape[0]), means-stds, means+stds, alpha=0.3, label='mean+-std')\n",
    "    plt.title(f'Last 100 episodes average reward on {VIZDOOM} using {ALGORITHM}')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Episode Reward')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join('./', 'episode_rewards.png'))\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def _plot_train_metric_results(data, model_title_name, model_fig_name):\n",
    "    data = data[:2, :800]\n",
    "    means = np.mean(data, axis=0)\n",
    "    stds = np.std(data, axis=0)\n",
    "\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    plt.plot(means, label='mean')\n",
    "    plt.fill_between(range(means.shape[0]), means-stds, means+stds, alpha=0.3, label='mean+-std')\n",
    "    plt.title(f'{model_title_name} evolution on {VIZDOOM} using {ALGORITHM}')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel(f'{model_title_name} ')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join('./', f'{model_fig_name}.png'))\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "\n",
    "_plot_rewards_results(rewards)\n",
    "_plot_train_metric_results(actor_loss, 'Actor Loss', 'actor_loss')\n",
    "_plot_train_metric_results(critic_loss, 'Critic Loss', 'critic_loss')\n",
    "_plot_train_metric_results(kl_divergence, 'KL Divergence', 'kl_divergence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vizdoom.vizdoom import DoomGame, ScreenFormat, ScreenResolution\n",
    "from constants import BIPEDAL\n",
    "from PPO.PPO_agent import  ContinuousPPOAgent\n",
    "\n",
    "import os\n",
    "import gym\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "\n",
    "game = DoomGame()\n",
    "game.load_config('./environments/vizdoom_files/basic.cfg')\n",
    "game.set_screen_resolution(ScreenResolution.RES_640X480)\n",
    "game.set_screen_format(ScreenFormat.RGB24)\n",
    "game.set_window_visible(True)\n",
    "game.set_sound_enabled(False)\n",
    "game.set_render_hud(True)\n",
    "game.init()\n",
    "\n",
    "\n",
    "game.new_episode()\n",
    "frame = game.get_state().screen_buffer\n",
    "\n",
    "img = Image.fromarray(frame)\n",
    "img.save(os.path.join('./', f'basic_frame.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0700c7f74b45c332d3cae75f71229e241bbc846b934be310d892912689fa2754"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
